{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProgLangQuests_base(quests_dict, req):\n",
    "    #req = \"https://stackoverflow.com/questions/tagged/\"+lang\n",
    "    r = requests.get(req)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    for i in soup.find_all('div', attrs={\"class\": [\"summary\"]}):\n",
    "        soup.find_all('div', attrs={\"class\": [\"summary\"]})\n",
    "        quests_dict[i.find('a').text]=i.find('a')['href']\n",
    "    return quests_dict, soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProgLangQuests(tags):\n",
    "    sof = \"https://stackoverflow.com\"\n",
    "    base = \"/questions/tagged/\"\n",
    "    new_req = sof+base+tags\n",
    "    quests_dict = {}\n",
    "    while True:\n",
    "        quests_dict, soup = ProgLangQuests_base(quests_dict, new_req)\n",
    "        next_page = soup.find_all('div', attrs={\"class\": [\"pager fl\"]})[0].find_all('a', attrs={\"rel\": [\"next\"]})\n",
    "        if len(next_page)==0:\n",
    "            return quests_dict\n",
    "        else:\n",
    "            next_page_link = next_page[0]['href']\n",
    "        new_req = sof+next_page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags='python+list+sorting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi2=ProgLangQuests(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer(q_dict, near_q):\n",
    "    sof = \"https://stackoverflow.com\"\n",
    "    nearest_quest=q_dict[near_q]\n",
    "    link = sof+nearest_quest\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    print(soup.find_all('div', attrs={\"id\": [\"answers\"]})[0].find_all('div', attrs={\"class\": [\"post-text\"]})[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"post-text\" itemprop=\"text\">\n",
      "<p>A full sort is unnecessary here. You can use <a href=\"https://docs.python.org/3.6/library/heapq.html#heapq.nsmallest\" rel=\"nofollow noreferrer\"><code>heap.nsmallest</code></a> followed by a list comprehension:</p>\n",
      "<pre><code>from heapq import nsmallest\n",
      "from operator import itemgetter\n",
      "\n",
      "list_a = [['A', 12.1], ['B', 15.6], ['C', 9.8], ['D', 12.1], ['F', 96.3]]\n",
      "\n",
      "second_largest_val = nsmallest(2, map(itemgetter(1), list_a))[1]\n",
      "res = [key for key, val in list_a if val == second_largest_val]\n",
      "\n",
      "# ['A', 'D']\n",
      "</code></pre>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "Answer(didi2, 'Accessing first element of a sorted nested list for second smallest second element')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
